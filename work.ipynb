{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce107b6",
   "metadata": {
    "id": "8ce107b6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44a670f",
   "metadata": {
    "id": "b44a670f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import deque\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from os import listdir\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3w2qLLeO5gtY",
   "metadata": {
    "id": "3w2qLLeO5gtY"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qENLpnnkzIWU",
   "metadata": {
    "id": "qENLpnnkzIWU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "w3mJHG1Cy5yZ",
   "metadata": {
    "id": "w3mJHG1Cy5yZ"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "train_df = pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GzVkng_Jy_hL",
   "metadata": {
    "id": "GzVkng_Jy_hL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d811193",
   "metadata": {
    "id": "9d811193"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "114cd773",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "114cd773",
    "outputId": "9a06535b-b17f-4866-83cc-69e8a2d250ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['we consider the problem of utility maximization for investors with power utility functions. building on the earlier work larsen et al. (2016), we prove that the value of the problem is a frechet-differentiable function of the drift of the price process, provided that this drift lies in a suitable banach space.   we then study optimal investment problems with non-markovian driving processes. in such models there is no hope to get a formula for the achievable maximal utility. applying results of the first part of the paper we provide first order expansions for certain problems involving fractional brownian motion either in the drift or in the volatility. we also point out how asymptotic results can be derived for models with strong mean reversion.',\n",
       "        'in this paper we provide an explicit formula for calculating the boolean number of a ferrers graph. by previous work of the last two authors, this determines the homotopy type of the boolean complex of the graph. specializing to staircase shapes, we show that the boolean numbers of the associated ferrers graphs are the genocchi numbers of the second kind, and obtain a relation between the legendre-stirling numbers and the genocchi numbers of the second kind. in another application, we compute the boolean number of a complete bipartite graph, corresponding to a rectangular ferrers shape, which is expressed in terms of the stirling numbers of the second kind. finally, we analyze the complexity of calculating the boolean number of a ferrers graph using these results and show that it is a significant improvement over calculating by edge recursion.'],\n",
       "       dtype=object),\n",
       " array(['on optimal investment with processes of long or negative memory',\n",
       "        'boolean complexes for ferrers graphs'], dtype=object))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_df[:2]['abstract'].values,\n",
    "train_df[:2]['title'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88de9086",
   "metadata": {
    "id": "88de9086"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe1c8fbd",
   "metadata": {
    "id": "fe1c8fbd"
   },
   "outputs": [],
   "source": [
    "train_df.columns=['question', 'answer']\n",
    "test_df.columns=['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eccb1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7eccb1f6",
    "outputId": "5e0c0f5b-9eeb-4143-df57-7e71a1ee31a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question', 'answer'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e23ee0c2",
   "metadata": {
    "id": "e23ee0c2",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ed02662",
   "metadata": {
    "id": "7ed02662"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b4c3128",
   "metadata": {
    "id": "4b4c3128"
   },
   "outputs": [],
   "source": [
    "all_texts = np.array(list(chain((train_df['question'], train_df['answer'])))).reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adafc4df",
   "metadata": {
    "id": "adafc4df"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f2421cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8f2421cc",
    "outputId": "dcc05009-2c7c-4c48-87a4-938ec0ed666a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa4c97a",
   "metadata": {
    "id": "2aa4c97a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cf75045",
   "metadata": {
    "id": "7cf75045"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9a38697",
   "metadata": {
    "id": "b9a38697"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self, pad_token=\"<PAD>\", unk_token=\"<UNKNOWN>\"):\n",
    "        \"\"\"\n",
    "        Инициализируем словарь с базовыми токенами.\n",
    "        \"\"\"\n",
    "        self.pad_token = pad_token\n",
    "        self.unk_token = unk_token\n",
    "        self.word2idx = {pad_token: 0, unk_token: 1}\n",
    "        self.idx2word = [pad_token, unk_token]\n",
    "\n",
    "    def add_word(self, word):\n",
    "        \"\"\"\n",
    "        Добавляем слово в словарь, если его еще нет.\n",
    "        \"\"\"\n",
    "        if word not in self.word2idx:\n",
    "            self.word2idx[word] = len(self.idx2word)\n",
    "            self.idx2word.append(word)\n",
    "\n",
    "    def encode(self, text):\n",
    "        \"\"\"\n",
    "        Преобразуем список слов в список индексов.\n",
    "        Если слово отсутствует в словаре, заменяем его на <UNKNOWN>.\n",
    "        \"\"\"\n",
    "        return [self.word2idx.get(word, self.word2idx[self.unk_token]) for word in text]\n",
    "\n",
    "    def decode(self, indices):\n",
    "        \"\"\"\n",
    "        Преобразуем список индексов в список слов.\n",
    "        \"\"\"\n",
    "        return [self.idx2word[idx] for idx in indices]\n",
    "\n",
    "\n",
    "    def build_vocabulary(self, sequences,  min_frequency=1 , max_frequency=19610000001961):\n",
    "        \"\"\"\n",
    "        Строим словарь на основе переданных последовательностей.\n",
    "        Каждая последовательность — это список слов.\n",
    "        Слова добавляются в словарь в порядке убывания их частоты.\n",
    "        \"\"\"\n",
    "\n",
    "        # Добавляем слова в порядке убывания частоты\n",
    "        [vocab.add_word(word=word) for word , frequency in Counter(\n",
    "                                                    tuple(chain.from_iterable(\n",
    "                                                        [sequence.split() for sequence in sequences]))\n",
    "                                                          ).items() if min_frequency<frequency<max_frequency]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Возвращаем размер словаря.\n",
    "        \"\"\"\n",
    "        return len(self.idx2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7eb9802",
   "metadata": {
    "id": "d7eb9802"
   },
   "outputs": [],
   "source": [
    "vocab=Vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0453d543",
   "metadata": {
    "id": "0453d543"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd6c2554",
   "metadata": {
    "id": "fd6c2554"
   },
   "outputs": [],
   "source": [
    "vocab.build_vocabulary(sequences=all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aca6ae4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aca6ae4f",
    "outputId": "b6c2c537-8059-4902-eaa4-2b0726cb7711"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223953"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd63a7",
   "metadata": {
    "id": "42fd63a7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87d3478",
   "metadata": {
    "id": "d87d3478"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28068120",
   "metadata": {
    "id": "28068120"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019b8bd",
   "metadata": {
    "id": "5019b8bd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba431976",
   "metadata": {
    "id": "ba431976"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, vocab, max_question_length, max_answer_length):\n",
    "        # Кодируем все вопросы и ответы\n",
    "        self.data = [(vocab.encode(question), vocab.encode(answer)) for question, answer in data]\n",
    "        self.max_question_length = max_question_length\n",
    "        self.max_answer_length = max_answer_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        question, answer = self.data[index]\n",
    "        # Паддинг всех вопросов и ответов до максимальной длины\n",
    "        question = question[:self.max_question_length] + [1] * (self.max_question_length - len(question))  # Паддинг для вопроса\n",
    "        answer = answer[:self.max_answer_length] + [1] * (self.max_answer_length - len(answer))  # Паддинг для ответа\n",
    "        return torch.tensor(question), torch.tensor(answer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Функция для обработки батчей с паддингом\n",
    "def collate_fn(batch):\n",
    "    questions, answers = zip(*batch)\n",
    "\n",
    "    # Паддинг последовательностей до одинаковой длины\n",
    "    pad_questions = pad_sequence([torch.tensor(question) for question in questions], batch_first=True, padding_value=1)  # pad_value=1 для <pad>\n",
    "    pad_answers = pad_sequence([torch.tensor(answer) for answer in answers], batch_first=True, padding_value=1)\n",
    "\n",
    "    return pad_questions, pad_answers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Разделение датасета\n",
    "dataset = TextDataset(data=train_df.values, vocab=vocab,\n",
    "                      max_question_length=len(train_df.question.max()),\n",
    "                      max_answer_length=len(train_df.answer.max()))\n",
    "\n",
    "# Размеры для разделения\n",
    "train_size = int(0.75 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size  # Остаток для теста\n",
    "\n",
    "# Разделение датасета\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "\n",
    "# Создание DataLoader'ов для каждой части\n",
    "batch_size = 64 # Для демонстрации используем маленький размер батча\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ff4989",
   "metadata": {
    "id": "f7ff4989"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e55ca0",
   "metadata": {
    "id": "c4e55ca0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4834c181",
   "metadata": {
    "id": "4834c181"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a521437",
   "metadata": {
    "id": "5a521437"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97edb21",
   "metadata": {
    "id": "a97edb21"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c8881",
   "metadata": {
    "id": "c40c8881"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0dc76",
   "metadata": {
    "id": "6eb0dc76"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37df310d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37df310d",
    "outputId": "9c21e9cf-1259-493e-ca31-54ae0bd61cb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223953"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cdf7ab8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cdf7ab8",
    "outputId": "d6f84654-399a-4255-9454-81826e08dab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Паддинговые вопросы:\n",
      "torch.Size([64, 821])\n",
      "Паддинговые ответы:\n",
      "torch.Size([64, 58])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Пример итерации по train_loader\n",
    "for batch in train_loader:\n",
    "    pad_questions, pad_answers = batch\n",
    "    print(f\"Паддинговые вопросы:\\n{pad_questions.size()}\")\n",
    "    print(f\"Паддинговые ответы:\\n{pad_answers.size()}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b86792",
   "metadata": {
    "id": "89b86792"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9db925",
   "metadata": {
    "id": "9a9db925"
   },
   "outputs": [],
   "source": [
    "# $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d10f87d",
   "metadata": {
    "id": "8d10f87d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba8998c",
   "metadata": {
    "id": "0ba8998c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab9c6c48",
   "metadata": {
    "id": "ab9c6c48"
   },
   "outputs": [],
   "source": [
    "# Параметры модели\n",
    "embedding_dim = 400\n",
    "hidden_size = 64\n",
    "output_size = 58\n",
    "vocab_size = len(vocab.idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a876a12",
   "metadata": {
    "id": "2a876a12"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66494428",
   "metadata": {
    "id": "66494428"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f0544b",
   "metadata": {
    "id": "99f0544b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8725215",
   "metadata": {
    "id": "a8725215"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784997b9",
   "metadata": {
    "id": "784997b9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91332803",
   "metadata": {
    "id": "91332803"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b8e7ba",
   "metadata": {
    "id": "e3b8e7ba"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad5db1b",
   "metadata": {
    "id": "4ad5db1b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b24601",
   "metadata": {
    "id": "d9b24601"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09bcec2",
   "metadata": {
    "id": "a09bcec2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedaef88",
   "metadata": {
    "id": "eedaef88"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b37279",
   "metadata": {
    "id": "d0b37279"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mLOuXGtN1EYG",
   "metadata": {
    "id": "mLOuXGtN1EYG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe47cb1",
   "metadata": {
    "id": "fbe47cb1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b5cf99",
   "metadata": {
    "id": "f8b5cf99"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "031f50e2",
   "metadata": {
    "id": "031f50e2"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    questions, answers = zip(*batch)\n",
    "\n",
    "    # Паддинг последовательностей до одинаковой длины\n",
    "    pad_questions = pad_sequence(questions, batch_first=True, padding_value=1)  # pad_value=1 для <pad>\n",
    "    pad_answers = pad_sequence(answers, batch_first=True, padding_value=1)\n",
    "\n",
    "    # Преобразуем тип для совместимости с моделью\n",
    "    pad_questions = pad_questions.float()\n",
    "    pad_answers = pad_answers.long()  # Для CrossEntropyLoss\n",
    "    return pad_questions, pad_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "626410a2",
   "metadata": {
    "id": "626410a2"
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, vocab, max_question_length, max_answer_length):\n",
    "        # Кодируем все вопросы и ответы\n",
    "        self.data = [(vocab.encode(question), vocab.encode(answer)) for question, answer in data]\n",
    "        self.max_question_length = max_question_length\n",
    "        self.max_answer_length = max_answer_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        question, answer = self.data[index]\n",
    "        # Паддинг всех вопросов и ответов до максимальной длины\n",
    "        question = question[:self.max_question_length] + [1] * (self.max_question_length - len(question))  # Паддинг для вопроса\n",
    "        answer = answer[:self.max_answer_length] + [1] * (self.max_answer_length - len(answer))  # Паддинг для ответа\n",
    "        return torch.tensor(question, dtype=torch.float32), torch.tensor(answer, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d22626d3",
   "metadata": {
    "id": "d22626d3"
   },
   "outputs": [],
   "source": [
    "batch_size = 128  # Размер батча для отладки\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7ff89d6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ff89d6b",
    "outputId": "31739f90-5e53-4746-9a32-229e13e15203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions shape: torch.Size([128, 821])\n",
      "Answers shape: torch.Size([128, 58])\n"
     ]
    }
   ],
   "source": [
    "for questions, answers in train_loader:\n",
    "    print(\"Questions shape:\", questions.shape)  # (batch_size, max_sequence_length)\n",
    "    print(\"Answers shape:\", answers.shape)      # (batch_size, max_sequence_length)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a63754",
   "metadata": {
    "id": "68a63754"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f74398",
   "metadata": {
    "id": "72f74398"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "10a11973",
   "metadata": {
    "id": "10a11973"
   },
   "outputs": [],
   "source": [
    "hidden_size = 256  # Размер скрытого слоя\n",
    "output_size = 58   # Количество возможных токенов в ответе\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b10aa92e",
   "metadata": {
    "id": "b10aa92e"
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size, num_layers=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)  # Слой эмбеддингов\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # Преобразование токенов в эмбеддинги\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        output = self.fc(ht[-1])  # Используем последний скрытый слой\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "80326a12",
   "metadata": {
    "id": "80326a12"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b38fb04d",
   "metadata": {
    "id": "b38fb04d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d859c5e",
   "metadata": {
    "id": "6d859c5e"
   },
   "outputs": [],
   "source": [
    "\n",
    "vocab_size = len(vocab.idx2word)  # Размер словаря\n",
    "input_size = 400  # Размер эмбеддинга\n",
    "embedding_dim = 400              # Размерность эмбеддингов\n",
    "hidden_size = 256                # Размерность скрытого слоя\n",
    "output_size = 58                 # Количество классов (или размер словаря ответов)\n",
    "max_sequence_length = 821\n",
    "\n",
    "model = LSTMModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    output_size=output_size\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "721f5526",
   "metadata": {
    "id": "721f5526"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # Игнорируем <pad>\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb334b25",
   "metadata": {
    "id": "cb334b25"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "623dfa05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "623dfa05",
    "outputId": "a0229d27-42b2-44b0-c9c9-dc2a027e9a1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13f8a0a",
   "metadata": {
    "id": "c13f8a0a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410186db",
   "metadata": {
    "id": "410186db"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ed8c5",
   "metadata": {
    "id": "2a9ed8c5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40cfc275",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40cfc275",
    "outputId": "bd822458-9e39-45e7-e41d-61bd8fd6ba59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0---->tensor(1111383.2500, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "1---->tensor(1058081.8750, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "2---->tensor(1163778.2500, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "3---->tensor(1096949.5000, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "4---->tensor(1143338.7500, device='cuda:0', grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for index ,(questions, answers) in enumerate(train_loader):\n",
    "    questions, answers = questions.to(device), answers.to(device)\n",
    "\n",
    "    # Прогон через модель\n",
    "    outputs = model(questions.long())  # Размерность: (batch_size, output_size)\n",
    "\n",
    "    # Вычисляем потери\n",
    "\n",
    "\n",
    "    loss = criterion(outputs.float(), answers.float())\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(index,loss, sep=\"---->\")\n",
    "    if index>3:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8015c5bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8015c5bc",
    "outputId": "6c7134c7-5ac1-4c38-a8f3-1026ba4252eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b415687",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b415687",
    "outputId": "7977dba4-6811-412f-9e9f-1a4e52989b92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 58])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a39f9ac5",
   "metadata": {
    "id": "a39f9ac5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "780ec81d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "780ec81d",
    "outputId": "1b60bb30-3db2-45a8-9494-46ba4aeb24a1"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-1b08254d335d>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Теперь можно вычислить потери\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "# Размерности\n",
    "# Преобразуем outputs: [batch_size, seq_length, vocab_size] -> [batch_size * seq_length, vocab_size]\n",
    "outputs = outputs.view(-1)  # Это будет [batch_size * seq_length, vocab_size]\n",
    "\n",
    "# Преобразуем answers: [batch_size, seq_length] -> [batch_size * seq_length]\n",
    "answers = answers.view(-1).float()  # Это будет [batch_size * seq_length]\n",
    "\n",
    "# Убедимся, что answers имеют тип long\n",
    "\n",
    "# Теперь можно вычислить потери\n",
    "loss = criterion(outputs, answers)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(f\"Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812dedf5",
   "metadata": {
    "id": "812dedf5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b752a4a",
   "metadata": {
    "id": "0b752a4a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac4005",
   "metadata": {
    "id": "b9ac4005"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c810e75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "0c810e75",
    "outputId": "62957a01-be02-43f2-ec92-f3e6bdee4fe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4211e+08, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.4579e+08, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.5415e+08, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.4369e+08, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.4937e+08, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.4503e+08, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.3925e+08, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.4506e+08, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.4565e+08, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.5030e+08, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.4887e+08, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.4301e+08, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.4180e+08, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.4444e+08, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.4383e+08, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.4598e+08, device='cuda:0', grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-6b015a83fcf8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[1;32m    522\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     def backward(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disable_current_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0mguard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DisableFuncTorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    623\u001b[0m                         \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                         \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    355\u001b[0m         )\n\u001b[1;32m    356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             nonzero_finite_vals = torch.masked_select(\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mtensor_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for questions, answers in train_loader:\n",
    "    questions, answers = questions.to(device), answers.to(device)\n",
    "\n",
    "    # Прогон через модель\n",
    "    outputs = model(questions.long())  # Размерность: (batch_size, output_size)\n",
    "\n",
    "    outputs = outputs.view(-1)  # Это будет [batch_size * seq_length, vocab_size]\n",
    "\n",
    "    answers = answers.view(-1).float()  # Это будет [batch_size * seq_length]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    loss = criterion(outputs, answers)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a0eef",
   "metadata": {
    "id": "643a0eef"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a29aa",
   "metadata": {
    "id": "d62a29aa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd1499e",
   "metadata": {
    "id": "efd1499e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68a4fee",
   "metadata": {
    "id": "b68a4fee"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba07104d",
   "metadata": {
    "id": "ba07104d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a7537",
   "metadata": {
    "id": "520a7537"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c98ba878",
   "metadata": {
    "id": "c98ba878"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # Игнорируем <pad>\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ae3e600",
   "metadata": {
    "id": "7ae3e600"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(model, train_loader, val_loader, optimizer, criterion, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for questions, answers in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            questions, answers = questions.to(device), answers.to(device)\n",
    "            outputs = model(questions.long())  # Размерность: (batch_size, output_size)\n",
    "            loss = criterion(outputs.float(), answers.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for questions, answers in tqdm(val_loader):\n",
    "                questions, answers = questions.to(device), answers.to(device)\n",
    "                outputs = model(questions.long())  # Размерность: (batch_size, output_size)\n",
    "                loss = criterion(outputs.float(), answers.float())\n",
    "                # optimizer.step()\n",
    "                val_loss += loss.item()\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Вызов функции обучения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "37ffb1ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "id": "37ffb1ae",
    "outputId": "f4db9e72-bfba-4bc6-9a75-3dbcf33ce399"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792/792 [04:44<00:00,  2.79it/s]\n",
      "100%|██████████| 106/106 [00:13<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1167109.1542, Val Loss: 1253332.6722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792/792 [04:42<00:00,  2.80it/s]\n",
      "100%|██████████| 106/106 [00:13<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 1142437.7648, Val Loss: 1169991.6981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792/792 [04:41<00:00,  2.81it/s]\n",
      "100%|██████████| 106/106 [00:13<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 1137492.4792, Val Loss: 1173739.8066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792/792 [04:40<00:00,  2.82it/s]\n",
      "100%|██████████| 106/106 [00:13<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 1145150.6968, Val Loss: 1200444.5920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792/792 [04:40<00:00,  2.82it/s]\n",
      "100%|██████████| 106/106 [00:13<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 1138283.6555, Val Loss: 1146684.5837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792/792 [04:40<00:00,  2.82it/s]\n",
      "100%|██████████| 106/106 [00:13<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 1138900.0866, Val Loss: 1147318.3325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 75/792 [00:27<04:18,  2.77it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-fabdbc117f46>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-d500776028f4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, optimizer, criterion, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "IS8Y8qFT31G7",
   "metadata": {
    "id": "IS8Y8qFT31G7"
   },
   "outputs": [],
   "source": [
    "# prompt: how to save torch model weights\n",
    "\n",
    "# Save the model's state_dict()\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Veq7sdLA76I0",
   "metadata": {
    "id": "Veq7sdLA76I0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OShQgkvJ-8pw",
   "metadata": {
    "id": "OShQgkvJ-8pw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_KXPSeKT-8mh",
   "metadata": {
    "id": "_KXPSeKT-8mh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lvkCSUB5-8im",
   "metadata": {
    "id": "lvkCSUB5-8im"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BeOlXxfS-8cg",
   "metadata": {
    "id": "BeOlXxfS-8cg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XT2vy9wq-8ZI",
   "metadata": {
    "id": "XT2vy9wq-8ZI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-CKoIT2a-8Rc",
   "metadata": {
    "id": "-CKoIT2a-8Rc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jWifagCy-8N2",
   "metadata": {
    "id": "jWifagCy-8N2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wgnPSBma-8I9",
   "metadata": {
    "id": "wgnPSBma-8I9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QyQiwo7D-8Dc",
   "metadata": {
    "id": "QyQiwo7D-8Dc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jith5bnl-783",
   "metadata": {
    "id": "jith5bnl-783"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lZeZu8bn-70g",
   "metadata": {
    "id": "lZeZu8bn-70g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0O_iYl1-7jH",
   "metadata": {
    "id": "d0O_iYl1-7jH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MZOrad5-752y",
   "metadata": {
    "id": "MZOrad5-752y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e92da23a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e92da23a",
    "outputId": "7db020c3-7b22-4947-d90b-d11daec283df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (embedding): Embedding(223953, 400)\n",
       "  (lstm): LSTM(400, 256, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=58, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18YZNzpK8HZ5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18YZNzpK8HZ5",
    "outputId": "a28f855a-7296-46f5-e66c-38dba3abf81d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61kN40d-9A_N",
   "metadata": {
    "id": "61kN40d-9A_N"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # Игнорируем <pad>\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "p8GhGRHD9Q8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "p8GhGRHD9Q8b",
    "outputId": "852e22ea-aa83-4263-d710-a65edeaeda37"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 87/1583 [00:10<02:56,  8.48it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-fabdbc117f46>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-d500776028f4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, optimizer, criterion, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qr349t2x9T84",
   "metadata": {
    "id": "qr349t2x9T84"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
